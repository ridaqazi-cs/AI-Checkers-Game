# ðŸ§  AI Checkers Game with Reinforcement Learning

This is a fully functional Checkers game implemented in **Python** using **Pygame**. It includes an **AI opponent powered by Q-learning**, a form of reinforcement learning. The AI can improve its gameplay via self-play and supports multiple difficulty levels, game modes, and a live stats dashboard.

---

## ðŸŽ® Game Features

- âœ… Human vs AI, Human vs Human, and AI vs AI modes  
- âœ… Multiple difficulty levels: Easy, Medium, Hard  
- âœ… Self-play training mode for reinforcement learning  
- âœ… Live statistics dashboard: win/loss/tie count and average moves  
- âœ… Turn indicators and endgame messages  
- âœ… Graphical menu for mode and difficulty selection

---

## ðŸ–¥ï¸ Requirements

- Python 3.9+
- Pygame  
- Numpy

Install dependencies:

```bash
pip install pygame numpy
```

---

## ðŸš€ Getting Started

1. Clone or download this repository.
2. Ensure you have `q_black.pkl` and `q_red.pkl` in the same folder.
3. Run the game:

```bash
python main.py
```

---

## ðŸ•¹ï¸ How to Play

### ðŸŽ›ï¸ Main Menu
When the game launches:

- Press:
  - `1` â†’ Human vs AI
  - `2` â†’ Human vs Human
  - `3` â†’ AI vs AI
  - `4` â†’ Training Mode
- Then press:
  - `E` â†’ Easy AI
  - `M` â†’ Medium AI
  - `H` â†’ Hard AI

The game begins once both are selected.

### ðŸ‘¤ Human Player Controls

- Click a piece of your color to select it.
- Valid destinations will be **highlighted in green**.
- Click a destination to move.
- Captures are forced if available.
- Multi-jumps are automatically handled.

### ðŸ¤– AI Behavior

- Uses **Q-learning** to learn optimal moves.
- Difficulty affects randomness:
  - **Easy**: very random
  - **Medium**: mostly smart
  - **Hard**: nearly optimal

---

## ðŸ“Š Statistics Dashboard

At the top-left of the screen:
- ðŸ•¹ï¸ Games Played  
- ðŸ”´ Red Wins  
- âš« Black Wins  
- ðŸ“‰ Average Moves per Game

---

## ðŸ Game Over

When a side wins:

- A message like **â€œRed Wins!â€** or **â€œBlack Wins!â€** appears.
- Press:
  - `R` to restart
  - `Q` to quit

---

## ðŸ§ª Self-Play Training Mode

To let AI play against itself:

1. From the menu, press `4` for **Training Mode**.
2. AI will learn by playing multiple episodes.
3. Use `.save()` methods in `ai.py` to save new Q-tables for stronger play.

> You can tweak the number of episodes and reward logic in the training loop for better performance.

---

## ðŸ“ File Structure

```
â”œâ”€â”€ main.py             # Main game loop & GUI
â”œâ”€â”€ ai.py               # Q-learning agent
â”œâ”€â”€ board.py            # Board logic
â”œâ”€â”€ piece.py            # Piece logic
â”œâ”€â”€ q_black.pkl         # AI knowledge (black side)
â”œâ”€â”€ q_red.pkl           # AI knowledge (red side)
```

---

## ðŸ§  How Q-Learning Works

- The board is encoded as a string state.
- Actions like `2,3->3,4` represent piece moves.
- Rewards:
  - +0.2 for captures
  - +1.0 for winning
  - -1.0 for losing
- Values are updated with the **Bellman equation**.

---

## ðŸ’¡ Possible Improvements

- Add save/load feature  
- Add sound effects  
- Visual animations  
- Online multiplayer  
- Upgrade to Deep Q-Networks (DQN)

---

## ðŸ‘¥ Team Members

- **Rida Qazi** â€“ 22k-4409  
- **Mashal Jawed** â€“ 22k-4552  
- **Abdul Wasey** â€“ 22k-4172  

---

## ðŸ“„ License

This project is licensed under the **MIT License**.
